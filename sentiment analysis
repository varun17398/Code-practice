import json
from textblob import TextBlob
import nltk.classify.util
from nltk.classify import NaiveBayesClassifier
from nltk.corpus import names
from nltk.corpus import stopwords
#from nltk.stem.wordnet import WordNetLemmatizer
#from nltk.stem.porter import PorterStemmer 
sw=stopwords.words("english")
#data=[]
f=open("cmnts.txt","r")
#f has the comments file
data=f.read()
data=data.lower()
l=[]
blob=TextBlob(data)
blob.correct()
for s in blob.sentences:
    l.append(list(s.words.singularize()))

def nested_remove(L, x):
    if x in L:
        L.remove(x)
    else:
        for element in L:
            if type(element) is list:
                nested_remove(element, x)
    
for k in l:
    for w in k:
        for q in sw:
            if(w==q):
                nested_remove(l,w)

def word_feats(words):
    return dict([(word,True) for word in words])


p=open("pos.txt","r")
post=p.read()
positivewords=post.split("\n")
n=open("neg.txt","r")
negt=n.read()
negativewords=negt.split("\n")

posfeatures=[(word_feats(pos),'pos') for pos in positivewords]
negfeatures=[(word_feats(neg),'neg') for neg in negativewords]

train_set=posfeatures+negfeatures

classifier=NaiveBayesClassifier.train(train_set)

neg=0
pos=0
k=0
for a in l:
    for word in a:
        classResult=classifier.classify(word_feats(word))
        k=k+1
        if classResult=='neg':
            neg=neg+1
        if classResult=='pos':
            pos=pos+1
print('Positive: '+str(float(pos)/k))
print('Negative: '+str(float(neg)/k))

#print(blob.sentiment)
#words=data.split(" ")
#print(blob.sentences)
#print(str(data))
